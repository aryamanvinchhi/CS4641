{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple XGBoost model which uses simple, basic feature engineering to still yield good results. Much of the ideas here are from the discussion forums on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra':\n",
    "    pd.read_csv('input/air_visit_data.csv'),\n",
    "    'as':\n",
    "    pd.read_csv('input/air_store_info.csv'),\n",
    "    'hs':\n",
    "    pd.read_csv('input/hpg_store_info.csv'),\n",
    "    'ar':\n",
    "    pd.read_csv('input/air_reserve.csv'),\n",
    "    'hr':\n",
    "    pd.read_csv('input/hpg_reserve.csv'),\n",
    "    'id':\n",
    "    pd.read_csv('input/store_id_relation.csv'),\n",
    "    'tes':\n",
    "    pd.read_csv('input/sample_submission.csv'),\n",
    "    'hol':\n",
    "    pd.read_csv('input/date_info.csv').rename(columns={\n",
    "        'calendar_date': 'visit_date'\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           air_store_id  visit_date  reserve_datetime_diff  reserve_visitors\n",
      "0  air_00a91d42b08b08d9  2016-10-31                      0                 2\n",
      "1  air_00a91d42b08b08d9  2016-12-05                      4                 9\n",
      "2  air_00a91d42b08b08d9  2016-12-14                      6                18\n",
      "3  air_00a91d42b08b08d9  2016-12-17                      6                 2\n",
      "4  air_00a91d42b08b08d9  2016-12-20                      2                 4\n",
      "           air_store_id  visit_date  reserve_datetime_diff  reserve_visitors\n",
      "0  air_00a91d42b08b08d9  2016-01-14                      3                 2\n",
      "1  air_00a91d42b08b08d9  2016-01-15                      6                 4\n",
      "2  air_00a91d42b08b08d9  2016-01-16                      3                 2\n",
      "3  air_00a91d42b08b08d9  2016-01-22                      3                 2\n",
      "4  air_00a91d42b08b08d9  2016-01-29                      6                 5\n"
     ]
    }
   ],
   "source": [
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar', 'hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime']) #convert to date-time format\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date #convert to date only\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime']) #same thing for reservations\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(\n",
    "        lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1) #use the difference as a feature\n",
    "    data[df] = data[df].groupby(\n",
    "        ['air_store_id', 'visit_datetime'], as_index=False)[[\n",
    "            'reserve_datetime_diff', 'reserve_visitors'\n",
    "        ]].sum().rename(columns={\n",
    "            'visit_datetime': 'visit_date'\n",
    "        })\n",
    "    print(data[df].head()) #get get info for each restaurant per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data - generate features for DOW, Year, Month, Date from original data\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "#String manipulation of test set to make sure data is consistent\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(\n",
    "    lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(\n",
    "    lambda x: '_'.join(x.split('_')[:2]))\n",
    "\n",
    "#Testing data - generate features for DOW, Year, Month, Date from orignal data\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now use the air_store_id to identify each unique store and generate some features\n",
    "#Features are min_visitors, mean_visitors, median_visitors, max_visitors, count_observations (number of visitors)\n",
    "\n",
    "#Stores df to store the information, will later be joined to training/testing data\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({\n",
    "            'air_store_id': unique_stores,\n",
    "            'dow': [i] * len(unique_stores)\n",
    "        }) for i in range(7)\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].min().rename(columns={\n",
    "        'visitors': 'min_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].mean().rename(columns={\n",
    "        'visitors': 'mean_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].median().rename(columns={\n",
    "        'visitors': 'median_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].max().rename(columns={\n",
    "        'visitors': 'max_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].count().rename(columns={\n",
    "        'visitors': 'count_observations'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "#Stores df now has all the generated features, we will merge it with air_store_info\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder() #Simple label encoding for categorical features for XGBoost\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "#Simple manipulation for holiday data\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "\n",
    "#merge the train and test sets to add holiday data\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date'])\n",
    "\n",
    "#similar merge but this time with stores data - contains our generated features\n",
    "train = pd.merge(data['tra'], stores, how='left', on=['air_store_id', 'dow'])\n",
    "test = pd.merge(data['tes'], stores, how='left', on=['air_store_id', 'dow'])\n",
    "\n",
    "for df in ['ar', 'hr']:\n",
    "    train = pd.merge(\n",
    "        train, data[df], how='left', on=['air_store_id', 'visit_date'])\n",
    "    test = pd.merge(\n",
    "        test, data[df], how='left', on=['air_store_id', 'visit_date'])\n",
    "\n",
    "col = [\n",
    "    c for c in train\n",
    "    if c not in ['id', 'air_store_id', 'visit_date', 'visitors']\n",
    "]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n",
      "(252108, 16) (252108,)\n"
     ]
    }
   ],
   "source": [
    "# XGB starter template borrowed from @anokas\n",
    "# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n",
    "\n",
    "print('Binding to float32')\n",
    "#Converting from float64 to float32\n",
    "for c, dtype in zip(train.columns, train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)\n",
    "\n",
    "train_x = train.drop(['air_store_id', 'visit_date', 'visitors'], axis=1)\n",
    "train_y = np.log1p(train['visitors'].values) #will predict log of visitors\n",
    "print(train_x.shape, train_y.shape)\n",
    "test_x = test.drop(['id', 'air_store_id', 'visit_date', 'visitors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:32:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# parameter tuning of xgboost\n",
    "# start from default setting\n",
    "boost_params = {'eval_metric': 'rmse'}\n",
    "xgb0 = xgb.XGBRegressor(\n",
    "    max_depth=8,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=10000,\n",
    "    objective='reg:linear',\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    "    **boost_params)\n",
    "\n",
    "xgb0.fit(train_x, train_y)\n",
    "predict_y = xgb0.predict(test_x)\n",
    "test['visitors'] = np.expm1(predict_y) #we found log of solution, exp to convert it back\n",
    "test[['id', 'visitors']].to_csv(\n",
    "    'xgb0_submission.csv', index=False, float_format='%.3f')  # LB0.495"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
